<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Brannon Tatum" />
    
    <link rel="shortcut icon" type="image/x-icon" href="../../img/favicon.ico">
    <title>Project 2: Modeling, Testing, and Predicting</title>
    <meta name="generator" content="Hugo 0.83.1" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="../../css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">
      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="../../"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="../../post/">BLOG</a></li>
        
        <li><a href="../../projects/">PROJECTS</a></li>
        
        <li><a href="../../resume/">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="../../project/project2/">Project 2: Modeling, Testing, and Predicting</a></strong>
          </h3>
        </div>
 
<div class="blog-title">
          <h4>
         May 7, 2021 
            &nbsp;&nbsp;
            
          </h4>
        </div>

        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              


<p><strong>0. Introduction (5 pts)</strong></p>
<p><em>The dataset I chose for this project is titled “Healthcare_Dataset_Stroke_data”. The dataset contains 12 variables including gender (“gender”/categorical), age (“age”/numeric), marital status (“ever_married”/categorical), work type (“work_type”/categorical), residence type (“residence_type”/categorical), average glucose level (avg_glucose_level/numeric), bmi (“bmi”/numeric), smoking status (“smoking_status”/categorical) and stroke (“stroke”, 1=yes, 0=no, binary). There are 5,110 observations for each of the 12 variables.</em></p>
<pre class="r"><code>healthcare_dataset_stroke_data &lt;- read_csv(&quot;healthcare-dataset-stroke-data.csv&quot;) #read in dataset
stroke &lt;- healthcare_dataset_stroke_data #renaming dataset for convenience
stroke &lt;-  stroke %&gt;% mutate(bmi=na_if(bmi, &quot;N/A&quot;)) #recoding NAs
stroke &lt;- stroke %&gt;% na.omit() #removing NAs
stroke$stroke&lt;-as.factor(stroke$stroke) #making stroke binary character
stroke$heart_disease&lt;-as.factor(stroke$heart_disease) 
stroke$bmi &lt;- as.numeric(as.character(stroke$bmi)) #making bmi numeric
head(stroke) #preview of dataset</code></pre>
<pre><code>## # A tibble: 6 x 12
## id gender age hypertension heart_disease ever_married
work_type Residence_type
## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;
## 1 9046 Male 67 0 1 Yes Private Urban
## 2 31112 Male 80 0 1 Yes Private Rural
## 3 60182 Female 49 0 0 Yes Private Urban
## 4 1665 Female 79 1 0 Yes Self-employed Rural
## 5 56669 Male 81 0 0 Yes Private Urban
## 6 53882 Male 74 1 1 Yes Private Rural
## # … with 4 more variables: avg_glucose_level &lt;dbl&gt;, bmi
&lt;dbl&gt;, smoking_status &lt;chr&gt;, stroke &lt;fct&gt;</code></pre>
<pre class="r"><code>library(sandwich) #for use later with bptest()
library(lmtest)

class_diag &lt;- function(probs,truth){
#CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV
tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
acc=sum(diag(tab))/sum(tab)
sens=tab[2,2]/colSums(tab)[2]
spec=tab[1,1]/colSums(tab)[1]
ppv=tab[2,2]/rowSums(tab)[2]
f1=2*(sens*ppv)/(sens+ppv)
if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
#CALCULATE EXACT AUC
ord&lt;-order(probs, decreasing=TRUE)
probs &lt;- probs[ord]; truth &lt;- truth[ord]
TPR=cumsum(truth)/max(1,sum(truth))
FPR=cumsum(!truth)/max(1,sum(!truth))
dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
n &lt;- length(TPR)
auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
data.frame(acc,sens,spec,ppv,f1,auc)
}</code></pre>
<p><strong>1. MANOVA (15 pts)</strong></p>
<p><em>A one-way MANOVA was conducted to determine the effect of work type on two dependent variables (age and average glucose level). Significant differences were found among work type for at least one of the dependent variables, Pillai trace=0.468, pseduo F(4, 10210)=389.79, p&lt;0.0001.</em>
<em>Univariate ANOVAs for each dependent variable were conducted as follow-up tests to the MANOVA, using the Bonferroni method for controlling Type I error rates for multiple comparisons. The univariate ANOVAs for average glucose level and age were also significant, F(4,5105)=16.612, p&lt;0.0001 and F(4,5105)=1110.1, p&lt;0.0001, respectively.</em>
<em>For post hoc tests, I used a significance level of 0.002, given I ran 1 MANOVA, 2 ANOVAs and 20 post-hoc t-tests. If left unadjusted, probability of a type I error is 1-0.95^23=0.693. Post hoc analysis was performed conducting pairwise comparisons to determine which work type differed in average glucose level and age. Average glucose level significantly differed for individuals working in government and individuals who do not work because they have children. It also significantly differed for individuals working in the private sector compare to individuals who do not work because they have children. Average glucose level also differed between those who are self-employed and individuals who do not work because they have children as well as between those who are self-employed and individuals working in the private sector. On the other hand, there is a significant mean difference in age between all work types except between those who have never worked and individuals who do not work because they have children.</em>
<em>Assumptions for running a MANOVA include random samples, independent observations, multivariate normality of DVs, homogeneity of within-group covariance matrices, linear relationships among DVs, no extreme univariate or multivariate outliers and no multicollinearity. Given the source of the dataset is confidential, we cannot confirm nor deny the random samples, independent observations assumption. Based on the mutivariate normality plots, this dataset may not pass the mutivariate normality assumption.</em></p>
<pre class="r"><code>man1 &lt;- manova(cbind(avg_glucose_level, age)~work_type, data=stroke)
summary(man1) #MANOVA</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## work_type 4 0.46884 375.4 8 9808 &lt; 2.2e-16 ***
## Residuals 4904
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>summary.aov(man1) #Univariate ANOVAs</code></pre>
<pre><code>## Response avg_glucose_level :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## work_type 4 129397 32349 16.6 1.609e-13 ***
## Residuals 4904 9556650 1949
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response age :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## work_type 4 1164201 291050 1071 &lt; 2.2e-16 ***
## Residuals 4904 1332662 272
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>pairwise.t.test(stroke$avg_glucose_level,stroke$work_type, p.adj=&quot;none&quot;) #t-test for average glucose level</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  stroke$avg_glucose_level and stroke$work_type 
## 
##               children Govt_job Never_worked Private
## Govt_job      5.3e-08  -        -            -      
## Never_worked  0.83169  0.23739  -            -      
## Private       8.7e-10  0.38353  0.30874      -      
## Self-employed 3.5e-15  0.03363  0.08683      0.00017
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(stroke$age,stroke$work_type, p.adj=&quot;none&quot;) #t-test for age</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  stroke$age and stroke$work_type 
## 
##               children Govt_job Never_worked Private
## Govt_job      &lt; 2e-16  -        -            -      
## Never_worked  0.0092   &lt; 2e-16  -            -      
## Private       &lt; 2e-16  3.9e-14  2.5e-16      -      
## Self-employed &lt; 2e-16  &lt; 2e-16  &lt; 2e-16      &lt; 2e-16
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>0.05/(20+1+2) #Bonferroni method for error</code></pre>
<pre><code>## [1] 0.002173913</code></pre>
<pre class="r"><code>1-0.95^23 #probability of type I error</code></pre>
<pre><code>## [1] 0.6926431</code></pre>
<pre class="r"><code>ggplot(stroke, aes(x = avg_glucose_level, y = age)) +
geom_point(alpha = .5) + geom_density_2d(h=2) + coord_fixed() + facet_wrap(~work_type)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-2-1.png" width="768" style="display: block; margin: auto;" /></p>
<p><strong>2. Randomization Test (10 pts)</strong></p>
<p><em>I am performing a randomization test to determine if the mean bmi is significantly different for individuals who have had a stroke compared to individuals who have not had a stroke. Ho: mean bmi is the same for individuals who have had a stroke and individuals who have not. Ha: mean bmi is different for individuals who have had a stroke and individuals who have not. After performing a randomization test on my data for mean difference, it was revealed that there is a significant different in mean bmi for individuals who have had a stroke and individuals who have not (p=0.0026).</em></p>
<pre class="r"><code>stroke%&gt;%group_by(stroke)%&gt;%
  summarize(means=mean(bmi)) %&gt;% summarize(`mean_diff`=diff(means)) #observed mean difference in bmi for those who have had stroke vs those who have not</code></pre>
<pre><code>## # A tibble: 1 x 1
##   mean_diff
##       &lt;dbl&gt;
## 1      1.65</code></pre>
<pre class="r"><code>rand_dist&lt;-vector() #randomization test
for(i in 1:5000){
new&lt;-data.frame(bmi=sample(stroke$bmi),stroke=stroke$stroke)
rand_dist[i]&lt;-mean(new[new$stroke==0,]$bmi)-
mean(new[new$stroke==1,]$bmi)}

mean(rand_dist&gt;1.648228 | rand_dist&lt; -1.648228) #two-tailed p value</code></pre>
<pre><code>## [1] 0.0042</code></pre>
<pre class="r"><code>{hist(rand_dist,main=&quot;&quot;,ylab=&quot;&quot;); abline(v = c(-1.648228, 1.648228),col=&quot;red&quot;)} #plot visualizing null distribution and test-statistic</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" /></p>
<p><strong>3. Linear Regression Model (40 pts)</strong></p>
<p><em>A linear regression predicting age from previous stroke history (1=yes,0=no) and bmi (after centering) revealed that 41.829 is the mean/predicted age for individuals who have never had a stroke with average bmi. For people with average bmi, people who have previously had a stroke have average/predicted age that is 26.810 greater than individuals who have never had a stroke, difference is significant (b=26, t=17.887, p&lt;0.05). Estimated slope for BMI on age for people who have never had a stroke is 0.974. Slope of BMI on age for individuals who have previously had a stroke is -1.5607 less than for individuals who have never had a stroke. The proportion of the variation in the age explained by this model is 0.1668. Residuals are not perfectly normally distributed, but ok, based on a histogram of residuals. Based on a bptest() for homoskedasticity and plotted residuals vs fitted values, we have heteroskadasticity (p&lt;0.05). Based on the plot modeling the relationship between residuals and fitted values, there is not a clear linear relationship (fanning). After recomputing regression results with robust standard errors, standard error values increased for stroke1, bmi_c and intercept but not for stroke1:bmi_c. We still reject the null hypothesis of homoskedasticity.</em></p>
<pre class="r"><code>stroke$bmi_c &lt;- stroke$bmi - mean(stroke$bmi)
fit&lt;-lm(age ~ stroke*bmi_c, data=stroke) #linear regression
summary(fit)</code></pre>
<pre><code>##
## Call:
## lm(formula = age ~ stroke * bmi_c, data = stroke)
##
## Residuals:
## Min 1Q Median 3Q Max
## -91.741 -17.461 -0.952 14.951 54.305
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 41.82879 0.30042 139.233 &lt; 2e-16 ***
## stroke1 26.81017 1.49882 17.887 &lt; 2e-16 ***
## bmi_c 0.97388 0.03799 25.635 &lt; 2e-16 ***
## stroke1:bmi_c -1.56070 0.22879 -6.822 1.01e-11 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 20.6 on 4905 degrees of freedom
## Multiple R-squared: 0.1668, Adjusted R-squared: 0.1662
## F-statistic: 327.2 on 3 and 4905 DF, p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>coeftest(fit, vcov = vcovHC(fit))[,1:2] #using robust standard errors</code></pre>
<pre><code>##                 Estimate Std. Error
## (Intercept)   41.8287910 0.30471635
## stroke1       26.8101652 0.89979839
## bmi_c          0.9738767 0.04951851
## stroke1:bmi_c -1.5606987 0.12521813</code></pre>
<pre class="r"><code>ggplot(stroke, aes(bmi,age, color = stroke)) + geom_smooth(method = &quot;lm&quot;, se = F, fullrange = T) + geom_point()+geom_vline(xintercept=0,lty=2)+geom_vline(xintercept=mean(stroke$bmi)) #plot of regression</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#assumptions
bptest(fit) #testing heteroskedasticity assumption: Ho: homoskedsastic!</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  fit
## BP = 102.99, df = 3, p-value &lt; 2.2e-16</code></pre>
<pre class="r"><code>resids&lt;-fit$residuals #creating residuals vs fitted values plot
fitvals&lt;-fit$fitted.values
plot(fitvals,resids); abline(h=0, col=&#39;red&#39;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-4-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow=c(1,2)); hist(resids); qqnorm(resids); qqline(resids, col=&#39;red&#39;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-4-3.png" width="768" style="display: block; margin: auto;" /></p>
<p><strong>4. Regression Model with Bootstrapped SEs (5 pts)</strong></p>
<p><em>After rerunning the same regression model with the interaction but computing bootstrapped standard errors, the SEs are very similar to the robust standard errors and slightly larger than the original SEs, likely indicating a smaller p-value.</em></p>
<pre class="r"><code>samp_distn&lt;-replicate(5000, {
boot_dat &lt;- sample_frac(stroke, replace=T) #take bootstrap sample of rows
fit_boot_se &lt;- lm(age~bmi_c*stroke, data=boot_dat) #fit model on bootstrap sample
coef(fit_boot_se) #save coefs
})

samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd) # estimated SEs</code></pre>
<pre><code>##   (Intercept)      bmi_c   stroke1 bmi_c:stroke1
## 1   0.3037416 0.04884177 0.9080543     0.1216805</code></pre>
<p><strong>5. Logistic Regression (30 pts)</strong></p>
<p><em>After running a logistic regression predicting heart disease (1=yes, 0=no) from age and bmi, it is revealed that when holding BMI constant, going up 1 year in age increases log-odds by 0.0804 and multiplies odds by a factor of e^1.0838. Going up 1 unit in BMI increases log-odds by 0.013443 and multiplies odds by a factor of e^1.0135. I computed a confusion matrix, revealing insights into the calculations for sensitivity, accuracy, specificity, precision and AUC. The accuracy of this regression was 0.95, sensitivity (TPR) was 0, specificity (TNR) was 1 and the auc was 0.849 (ppv not given). This means there are 0 true positives and zero false positives. Given a TPR of 0 and a TNR of 1, the model is not predicting individuals with heart disease very well. Additionally, an AUC of 0.849 indicates a decent, but not great, model. The ROC curve demonstrates how the model is not perfect as it curves up and to the right.</em></p>
<pre class="r"><code>maybe &lt;- stroke %&gt;% select(heart_disease, age, bmi) %&gt;% mutate(y=ifelse(heart_disease==&quot;1&quot;, 1, 0))
fit_log&lt;-glm(y~age + bmi,data=maybe,family=binomial(link=&quot;logit&quot;))
coeftest(fit_log)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -7.975447 0.522524 -15.2633 &lt;2e-16 ***
## age 0.080436 0.005280 15.2342 &lt;2e-16 ***
## bmi 0.013443 0.010625 1.2653 0.2058
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coef(fit_log))</code></pre>
<pre><code>## (Intercept)         age         bmi 
## 0.000343801 1.083759887 1.013533942</code></pre>
<pre class="r"><code>maybe$prob &lt;- predict(fit_log,type=&quot;response&quot;) #get predicted probabilities
maybe$predicted &lt;- ifelse(maybe$prob&gt;.5,&quot;heart disease&quot;,&quot;no heart disease&quot;) #get predicted outcomes
maybe$logit&lt;-predict(fit_log) #save predicted log-odds

#DENSITY PLOT
maybe%&gt;%ggplot()+geom_density(aes(logit,color=heart_disease,fill=heart_disease), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab(&quot;logit (log-odds)&quot;)+
  geom_rug(aes(logit,color=heart_disease)) #density plot</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-6-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#CONFUSION MATRIX
table(truth=maybe$heart_disease, prediction=maybe$predicted)%&gt;%addmargins #confusion matrix</code></pre>
<pre><code>##      prediction
## truth no heart disease  Sum
##   0               4666 4666
##   1                243  243
##   Sum             4909 4909</code></pre>
<pre class="r"><code>class_diag(maybe$prob,maybe$heart_disease) #sensitivity, accuracy, other measures</code></pre>
<pre><code>##         acc sens spec ppv  f1       auc
## 1 0.9504991    0    1 NaN NaN 0.8485652</code></pre>
<pre class="r"><code>#ROC PLOT
library(plotROC) #install.packages(plotROC)

#geom_roc needs actual outcome (0,1) and predicted probability (or predictor if just one) 
ROCplot&lt;-ggplot(maybe)+geom_roc(aes(d=y,m=age + bmi), n.cuts=0) 
ROCplot</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-6-2.png" width="768" style="display: block; margin: auto;" /></p>
<p><strong>6.Logistic Regression with all variables (25 pts)</strong></p>
<p><em>After performing a logistic regression predicting heart disease from all of the other variables, the accuracy was 0.950 (proportion of correctly classified individuals), sensitivity was 0.0205 (TPR), specificity was 0.998 (TNR), precision (PPV) was 0.417 and the AUC was 0.874. This model performs slightly better than the previous with a higher AUC, however, precision and sensitivity are both very low indicating the proportion of individuals with heart disease correctly classified is low and the proportion classified as having heart disease who actually do is low. After running a 10 fold CV with the same model, average out of sample accuracy was 0.95, sensitivity was 0.0221, specificity was 0.999 and the AUC was 0.868. The 10 fold CV resulted in worse performance out of sample, indicating over-fitting. Compared to the in-sample metrics, acc is about the same, sensitivity is slightly lower and specificity is the same. After performing LASSO on the same model, the variables retained are genderMale, age, average glucose level and stroke1. I then performed a 10-fold CV using only those variables retained. The out of sample AUC for this model was 0.869. Compared to the AUC from the previous logistic regression, this AUC is very slightly larger (0.869 vs 0.868), indicating this model is not much better than the previous model. Finally, this AUC is decent but not great.</em></p>
<pre class="r"><code>stroke2 &lt;- stroke %&gt;% select(-id,-bmi_c)
head(stroke2) </code></pre>
<pre><code>## # A tibble: 6 x 11
## gender age hypertension heart_disease ever_married
work_type Residence_type avg_glucose_lev…
## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;
## 1 Male 67 0 1 Yes Private Urban 229.
## 2 Male 80 0 1 Yes Private Rural 106.
## 3 Female 49 0 0 Yes Private Urban 171.
## 4 Female 79 1 0 Yes Self-employed Rural 174.
## 5 Male 81 0 0 Yes Private Urban 186.
## 6 Male 74 1 1 Yes Private Rural 70.1
## # … with 3 more variables: bmi &lt;dbl&gt;, smoking_status
&lt;chr&gt;, stroke &lt;fct&gt;</code></pre>
<pre class="r"><code>fit_all &lt;- glm(heart_disease~., data=stroke2, family=&quot;binomial&quot;) #logistic regression using all predictors
exp(coef(fit_all))</code></pre>
<pre><code>## (Intercept) genderMale genderOther
## 3.468360e-04 2.186341e+00 4.369913e-05
## age hypertension ever_marriedYes
## 1.085180e+00 1.229247e+00 7.398772e-01
## work_typeGovt_job work_typeNever_worked work_typePrivate
## 5.747176e-01 6.143198e-05 6.054248e-01
## work_typeSelf-employed Residence_typeUrban
avg_glucose_level
## 4.996263e-01 8.904092e-01 1.005050e+00
## bmi smoking_statusnever smoked smoking_statussmokes
## 1.004171e+00 7.946097e-01 1.791868e+00
## smoking_statusUnknown stroke1
## 8.389938e-01 1.388893e+00</code></pre>
<pre class="r"><code>prob2&lt;-predict(fit_all,type=&quot;response&quot;)
class_diag(prob2,stroke2$heart_disease)</code></pre>
<pre><code>## acc sens spec ppv f1 auc
## 1 0.9500917 0.02057613 0.9984998 0.4166667 0.03921569
0.8740905</code></pre>
<pre class="r"><code>#10 fold CV
set.seed(1234)
k=10

data &lt;- stroke2 %&gt;% sample_frac #put rows of dataset in random order
folds &lt;- ntile(1:nrow(data),n=10) #create fold labels

diags&lt;-NULL
for(i in 1:k){
  train &lt;- data[folds!=i,] #create training set (all but fold i)
  test &lt;- data[folds==i,] #create test set (just fold i)
  truth &lt;- test$heart_disease #save truth labels from fold i
  
  fit_last &lt;- glm(heart_disease~., data=stroke2, family=&quot;binomial&quot;)
  probs &lt;- predict(fit_last, newdata=test, type=&quot;response&quot;)
  
  diags&lt;-rbind(diags,class_diag(probs,truth))
}

summarize_all(diags,mean) #average diagnostics across all 10 folds</code></pre>
<pre><code>##        acc       sens      spec ppv  f1       auc
## 1 0.950091 0.02207005 0.9985037 NaN NaN 0.8729339</code></pre>
<pre class="r"><code>#LASSO
library(glmnet)
y&lt;-as.matrix(stroke2$heart_disease) #grab response
x&lt;-model.matrix(heart_disease~.,data=stroke2)[,-1] #grab predictors
head(x)</code></pre>
<pre><code>## genderMale genderOther age hypertension ever_marriedYes
work_typeGovt_job work_typeNever_worked
## 1 1 0 67 0 1 0 0
## 2 1 0 80 0 1 0 0
## 3 0 0 49 0 1 0 0
## 4 0 0 79 1 1 0 0
## 5 1 0 81 0 1 0 0
## 6 1 0 74 1 1 0 0
## work_typePrivate work_typeSelf-employed
Residence_typeUrban avg_glucose_level bmi
## 1 1 0 1 228.69 36.6
## 2 1 0 0 105.92 32.5
## 3 1 0 1 171.23 34.4
## 4 0 1 0 174.12 24.0
## 5 1 0 1 186.21 29.0
## 6 1 0 0 70.09 27.4
## smoking_statusnever smoked smoking_statussmokes
smoking_statusUnknown stroke1
## 1 0 0 0 1
## 2 1 0 0 1
## 3 0 1 0 1
## 4 1 0 0 1
## 5 0 0 0 1
## 6 1 0 0 1</code></pre>
<pre class="r"><code>cv&lt;-cv.glmnet(x,y,family=&quot;binomial&quot;)
lasso&lt;-glmnet(x,y,family=&quot;binomial&quot;,lambda=cv$lambda.1se)
coef(lasso) </code></pre>
<pre><code>## 17 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                                      s0
## (Intercept)                -6.004457958
## genderMale                  0.233279744
## genderOther                 .          
## age                         0.048761457
## hypertension                .          
## ever_marriedYes             .          
## work_typeGovt_job           .          
## work_typeNever_worked       .          
## work_typePrivate            .          
## work_typeSelf-employed      .          
## Residence_typeUrban         .          
## avg_glucose_level           0.003028001
## bmi                         .          
## smoking_statusnever smoked  .          
## smoking_statussmokes        .          
## smoking_statusUnknown       .          
## stroke1                     0.162234750</code></pre>
<pre class="r"><code>#10-fold CV with only LASSO selected variables
set.seed(1234)
k=10

data2 &lt;- stroke2 %&gt;% sample_frac #put rows of dataset in random order
folds &lt;- ntile(1:nrow(data),n=10) #create fold labels


diags&lt;-NULL
for(i in 1:k){
  train2 &lt;- data2[folds!=i,] #create training set (all but fold i)
  test2 &lt;- data2[folds==i,] #create test set (just fold i)
  truth2 &lt;- test2$heart_disease #save truth labels from fold i
  
  fit_final &lt;- glm(heart_disease~ gender + age + avg_glucose_level + stroke, data2, family=&quot;binomial&quot;)
  probs_final &lt;- predict(fit_final, newdata=test2, type=&quot;response&quot;)
  
  diags&lt;-rbind(diags,class_diag(probs_final,truth2))
}

diags%&gt;%summarize_all(mean)</code></pre>
<pre><code>##         acc       sens     spec ppv  f1       auc
## 1 0.9502947 0.01407005 0.999143 NaN NaN 0.8686514</code></pre>
<p>…</p>

            
        <hr>         <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div> 
            </div>
          </div>

   <hr>  <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 
        </div>
      </div>
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="../../js/docs.min.js"></script>
<script src="../../js/main.js"></script>

<script src="../../js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
